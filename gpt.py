# -*- coding: utf-8 -*-
"""
ç©å…· ChatGPT â€”â€” åŸºäº "AI = åŠ¨æ€åˆ†ç±»" ç†è®º (Wang, 2025)
æ ¸å¿ƒæœºåˆ¶ï¼šæ¯ä¸€æ­¥ç”Ÿæˆ = åœ¨è¯æ±‡è¡¨ä¸Šåšä¸€æ¬¡ä¸Šä¸‹æ–‡ç›¸å…³çš„åˆ†ç±»
"""


# 2. åŸºäºä¸Šä¸‹æ–‡çš„â€œåˆ†ç±»å™¨â€ï¼ˆæ¨¡æ‹ŸåŠ¨æ€è¯­ä¹‰ç±»åˆ«ï¼‰
def classify_next_token(context_tokens):
    """
    è¾“å…¥ï¼šå½“å‰ä¸Šä¸‹æ–‡ token åˆ—è¡¨
    è¾“å‡ºï¼šä» VOCAB ä¸­â€œåˆ†ç±»â€å‡ºæœ€å¯èƒ½çš„ä¸‹ä¸€ä¸ª token
    """
    if not context_tokens:
        return "hello"
    
    # è½¬ä¸º tuple ä¾¿äºåŒ¹é…
    ctx = tuple(context_tokens)
    last = ctx[-1]
    last2 = ctx[-2:] if len(ctx) >= 2 else ()
    last3 = ctx[-3:] if len(ctx) >= 3 else ()

    # è§„åˆ™ï¼šæ¨¡æ‹Ÿâ€œåŠ¨æ€æ„å»ºçš„è¯­ä¹‰ç±»åˆ«â€
    rules = {
        ("hello",): "hi",
        ("hi",): "how",
        ("how",): "are",
        ("how", "are"): "you",
        ("you",): "?",
        ("?",): "I",
        ("I",): "am",
        ("am",): "fine",
        ("fine",): "!",
        ("bye",): "see",
        ("see",): "you",
        ("you",): "later",  # æ³¨æ„ï¼šå’Œä¸Šé¢å†²çªï¼Œé é¡ºåºä¼˜å…ˆ

        ("what",): "is",
        ("what", "is"): "ai",
        ("ai",): "cool",
        ("cool",): "!",

        ("can",): "you",
        ("can", "you"): "do",
        ("do",): "math",
        ("math",): "2",
        ("2",): "+",
        ("+",): "4",
        ("4",): "=",
        ("=",): "6",
        ("6",): "!",

        ("why",): "is",
        ("why", "is"): "sky",
        ("sky",): "blue",
        ("blue",): "because",
        ("because",): "light",
        ("light",): "scatters",
        ("scatters",): "!",

        ("tell",): "me",
        ("tell", "me"): "about",
        ("about",): "cats",
        ("cats",): "are",
        ("are",): "nice",
        ("nice",): "!",

        # é»˜è®¤ fallback
        "default": "ok"
    }

    # ä¼˜å…ˆåŒ¹é…é•¿ä¸Šä¸‹æ–‡
    if last3 in rules:
        return rules[last3]
    if last2 in rules:
        return rules[last2]
    if (last,) in rules:
        return rules[(last,)]
    
    return rules["default"]

# 3. è‡ªå›å½’ç”Ÿæˆå‡½æ•°
def generate_response(prompt, history=[], max_tokens=15):
    """
    è¾“å…¥ prompt å’Œå†å²ï¼Œè¿”å›æ¨¡å‹ç”Ÿæˆçš„å®Œæ•´å¥å­
    """
    # åˆå¹¶å†å²å’Œå½“å‰ prompt
    tokens = (history + prompt.split())
    generated = []

    for _ in range(max_tokens):
        next_tok = classify_next_token(tokens)
        if next_tok in ["!", "?", "."]:  # ç®€æ˜“åœç”¨
            generated.append(next_tok)
            break
        generated.append(next_tok)
        tokens.append(next_tok)  # è‡ªå›å½’ï¼šæ–° token æˆä¸ºä¸‹ä¸€æ¬¡è¾“å…¥

    return " ".join(generated)

# 4. æ¨¡æ‹Ÿå¤šè½®å¯¹è¯ï¼ˆéäº¤äº’å¼ï¼Œç”¨äºæ¼”ç¤ºï¼‰
def demo_chat():
    history = []
    turns = [
        "hello",
        "what is ai",
        "can you do math",
        "why is sky blue",
        "tell me about cats",
        "bye"
    ]

    print("ğŸ¤– ç©å…· ChatGPTï¼ˆåŸºäºâ€˜åŠ¨æ€åˆ†ç±»â€™ç†è®ºï¼‰\n")
    for user_input in turns:
        print(f"ğŸ‘¤ User: {user_input}")
        response = generate_response(user_input, history=history)
        print(f"ğŸ¤– AI:   {response}\n")
        # æ›´æ–°å†å²ï¼ˆå¯é€‰ï¼šåªä¿ç•™æœ€è¿‘ N è½®ï¼‰
        history = (user_input.split() + response.split())[-20:]

if __name__ == "__main__":
    demo_chat()